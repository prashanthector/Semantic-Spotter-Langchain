{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f098df-d475-41aa-94fb-9db241100406",
   "metadata": {},
   "source": [
    "#                                            Semantic Spotter - Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa93172-1994-48ee-855f-f24f361db652",
   "metadata": {},
   "source": [
    "## Building Langchain based Email Search AI\n",
    "### Dataset: https://www.kaggle.com/code/xokent/email-thread-summary-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe785c-7045-45d1-a768-424de1bf9c2d",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Above Kaggle Dataset contains different email threads between different individuals. So it's very hard to get the insght of full conversation as the here about 21864 rows and each thread have multiple rows. For an outside person it's very hard to understand what these conversations are all about.\n",
    "\n",
    "## Solution\n",
    "So based on the problem building a QAChain or Conversational Chain will be apt application to get required information about the email conversations happening among different individuals.\n",
    "### So We will use Langchain for this particular problem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b277e2b2-27ee-461e-b338-b9ab4c79c528",
   "metadata": {},
   "source": [
    "### Step1: Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98cd953c-ba7e-450d-9e66-7663db9c25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6253ee-d835-44ce-8d0e-82a7c1c85e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.11/site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/lib/python3.11/site-packages (0.3.12)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-openai) (1.73.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44129df1-eaee-4085-a69a-3b60225c15b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.11/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/anaconda3/lib/python3.11/site-packages (from faiss-cpu) (2.1.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu python-dotenv tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be4ef0-3b7d-4adc-8f9f-b2093d148dbc",
   "metadata": {},
   "source": [
    "### Step2: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c127a9dd-2a43-4558-afa8-bf622c9a1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"email_thread_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e17f95da-17d4-49f5-b8d6-3ec756439c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"email_thread_summaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5632042a-2884-4124-b621-8f013c2deb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FW: Master Termination Log</td>\n",
       "      <td>2002-01-29 11:23:42</td>\n",
       "      <td>Gossett, Jeffrey C. JGOSSET</td>\n",
       "      <td>['Giron', 'Darron C. Dgiron', 'Love', 'Phillip...</td>\n",
       "      <td>\\n\\n -----Original Message-----\\nFrom: =09Ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FW: Master Termination Log</td>\n",
       "      <td>2002-01-31 12:50:00</td>\n",
       "      <td>Theriot, Kim S. KTHERIO</td>\n",
       "      <td>['Murphy', 'Melissa Mmurphy', 'Gossett', 'Jeff...</td>\n",
       "      <td>\\n\\n -----Original Message-----\\nFrom: =09Panu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>FW: Master Termination Log</td>\n",
       "      <td>2002-02-05 15:03:35</td>\n",
       "      <td>Theriot, Kim S. KTHERIO</td>\n",
       "      <td>['Murphy', 'Melissa Mmurphy', 'Anderson', 'Dia...</td>\n",
       "      <td>Note to Stephanie Panus....\\n\\nStephanie...ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>FW: Master Termination Log</td>\n",
       "      <td>2002-02-05 15:06:25</td>\n",
       "      <td>Theriot, Kim S. KTHERIO</td>\n",
       "      <td>['Hall', 'D. Todd Thall', 'Sweeney', 'Kevin Ks...</td>\n",
       "      <td>\\n\\n -----Original Message-----\\nFrom: =09Panu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>FW: Master Termination Log</td>\n",
       "      <td>2002-05-28 07:20:35</td>\n",
       "      <td>Kelly, Katherine L. KKELLY</td>\n",
       "      <td>['Germany', 'Chris Cgerman']</td>\n",
       "      <td>\\n\\n -----Original Message-----\\nFrom: =09McMi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21679</th>\n",
       "      <td>4166</td>\n",
       "      <td>vacation</td>\n",
       "      <td>2000-10-04 11:32:00</td>\n",
       "      <td>Sara Shackleton</td>\n",
       "      <td>['Gary Hickerson', 'Sheila Glover', 'Laurel Ad...</td>\n",
       "      <td>I will be on vacation from October 6- 13.  Als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21680</th>\n",
       "      <td>4167</td>\n",
       "      <td>web file</td>\n",
       "      <td>2001-03-18 22:57:00</td>\n",
       "      <td>Matt Smith</td>\n",
       "      <td>['Amanda Huble']</td>\n",
       "      <td>Amanda,\\n\\nCan you put this file in the approp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21681</th>\n",
       "      <td>4167</td>\n",
       "      <td>web file</td>\n",
       "      <td>2001-03-19 04:42:00</td>\n",
       "      <td>Matt Smith</td>\n",
       "      <td>['Amanda Huble']</td>\n",
       "      <td>Amanda,\\n\\nPlease move the file i sent you fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21682</th>\n",
       "      <td>4167</td>\n",
       "      <td>web file</td>\n",
       "      <td>2001-03-19 09:57:00</td>\n",
       "      <td>Matt Smith</td>\n",
       "      <td>['Amanda Huble &lt;Amanda Huble/NA/Enron@Enron']</td>\n",
       "      <td>Amanda,\\n\\nCan you put this file in the approp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21683</th>\n",
       "      <td>4167</td>\n",
       "      <td>web file</td>\n",
       "      <td>2001-03-19 15:42:00</td>\n",
       "      <td>Matt Smith</td>\n",
       "      <td>['Amanda Huble &lt;Amanda Huble/NA/Enron@Enron']</td>\n",
       "      <td>Amanda,\\n\\nPlease move the file i sent you fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21684 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       thread_id                     subject            timestamp  \\\n",
       "0              1  FW: Master Termination Log  2002-01-29 11:23:42   \n",
       "1              1  FW: Master Termination Log  2002-01-31 12:50:00   \n",
       "2              1  FW: Master Termination Log  2002-02-05 15:03:35   \n",
       "3              1  FW: Master Termination Log  2002-02-05 15:06:25   \n",
       "4              1  FW: Master Termination Log  2002-05-28 07:20:35   \n",
       "...          ...                         ...                  ...   \n",
       "21679       4166                    vacation  2000-10-04 11:32:00   \n",
       "21680       4167                    web file  2001-03-18 22:57:00   \n",
       "21681       4167                    web file  2001-03-19 04:42:00   \n",
       "21682       4167                    web file  2001-03-19 09:57:00   \n",
       "21683       4167                    web file  2001-03-19 15:42:00   \n",
       "\n",
       "                              from  \\\n",
       "0      Gossett, Jeffrey C. JGOSSET   \n",
       "1          Theriot, Kim S. KTHERIO   \n",
       "2          Theriot, Kim S. KTHERIO   \n",
       "3          Theriot, Kim S. KTHERIO   \n",
       "4       Kelly, Katherine L. KKELLY   \n",
       "...                            ...   \n",
       "21679              Sara Shackleton   \n",
       "21680                   Matt Smith   \n",
       "21681                   Matt Smith   \n",
       "21682                   Matt Smith   \n",
       "21683                   Matt Smith   \n",
       "\n",
       "                                                      to  \\\n",
       "0      ['Giron', 'Darron C. Dgiron', 'Love', 'Phillip...   \n",
       "1      ['Murphy', 'Melissa Mmurphy', 'Gossett', 'Jeff...   \n",
       "2      ['Murphy', 'Melissa Mmurphy', 'Anderson', 'Dia...   \n",
       "3      ['Hall', 'D. Todd Thall', 'Sweeney', 'Kevin Ks...   \n",
       "4                           ['Germany', 'Chris Cgerman']   \n",
       "...                                                  ...   \n",
       "21679  ['Gary Hickerson', 'Sheila Glover', 'Laurel Ad...   \n",
       "21680                                   ['Amanda Huble']   \n",
       "21681                                   ['Amanda Huble']   \n",
       "21682      ['Amanda Huble <Amanda Huble/NA/Enron@Enron']   \n",
       "21683      ['Amanda Huble <Amanda Huble/NA/Enron@Enron']   \n",
       "\n",
       "                                                    body  \n",
       "0      \\n\\n -----Original Message-----\\nFrom: =09Ther...  \n",
       "1      \\n\\n -----Original Message-----\\nFrom: =09Panu...  \n",
       "2      Note to Stephanie Panus....\\n\\nStephanie...ple...  \n",
       "3      \\n\\n -----Original Message-----\\nFrom: =09Panu...  \n",
       "4      \\n\\n -----Original Message-----\\nFrom: =09McMi...  \n",
       "...                                                  ...  \n",
       "21679  I will be on vacation from October 6- 13.  Als...  \n",
       "21680  Amanda,\\n\\nCan you put this file in the approp...  \n",
       "21681  Amanda,\\n\\nPlease move the file i sent you fro...  \n",
       "21682  Amanda,\\n\\nCan you put this file in the approp...  \n",
       "21683  Amanda,\\n\\nPlease move the file i sent you fro...  \n",
       "\n",
       "[21684 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "416a855f-64ba-4960-b963-5748cfa439c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The email thread discusses the Master Terminat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A lunch meeting has been scheduled for May 5th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ben is updating a friend on his progress with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The recipient of the email thread initially ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The email thread discusses the long form confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>4163</td>\n",
       "      <td>Peter Thompson has sent a memo to Kay Mann and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>4164</td>\n",
       "      <td>The email thread revolves around the sharing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>4165</td>\n",
       "      <td>Susan asks Emily about her plans for the weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>4166</td>\n",
       "      <td>Several employees will be on vacation during d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>4167</td>\n",
       "      <td>Mat has sent an email to Amanda requesting her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      thread_id                                            summary\n",
       "0             1  The email thread discusses the Master Terminat...\n",
       "1             2  A lunch meeting has been scheduled for May 5th...\n",
       "2             3  Ben is updating a friend on his progress with ...\n",
       "3             4  The recipient of the email thread initially ex...\n",
       "4             5  The email thread discusses the long form confi...\n",
       "...         ...                                                ...\n",
       "4162       4163  Peter Thompson has sent a memo to Kay Mann and...\n",
       "4163       4164  The email thread revolves around the sharing a...\n",
       "4164       4165  Susan asks Emily about her plans for the weeke...\n",
       "4165       4166  Several employees will be on vacation during d...\n",
       "4166       4167  Mat has sent an email to Amanda requesting her...\n",
       "\n",
       "[4167 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294cdde7-818e-4d16-986b-1e9bf1f5d5be",
   "metadata": {},
   "source": [
    "#### Creating Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3860d15-8c5d-47f7-9bf3-6475f0da37bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/5f3_2qps7jj4s6z2p3k48qjh0000gn/T/ipykernel_75596/3825038182.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df1_cleaned_merged = df1.groupby(\"thread_id\").apply(merge_metadata).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create metadata_dict\n",
    "df1[\"metadata_dict\"] = df1.apply(lambda row: {\n",
    "    \"thread_id\": row[\"thread_id\"],\n",
    "    \"subject\": row[\"subject\"],\n",
    "    \"timestamp\": row[\"timestamp\"],\n",
    "    \"from\": row[\"from\"],\n",
    "    \"to\": row[\"to\"],\n",
    "    \"body\": row[\"body\"]\n",
    "}, axis=1)\n",
    "\n",
    "# Step 2: Group by thread_id and merge metadata_dicts\n",
    "def merge_metadata(group):\n",
    "    first_row = group.iloc[0][\"metadata_dict\"].copy()  # Take metadata from the first message\n",
    "    merged_body = \"\\n\\n\".join(row[\"body\"] for row in group[\"metadata_dict\"])  # Merge all bodies\n",
    "    first_row[\"body\"] = merged_body\n",
    "    return pd.Series({\n",
    "        \"thread_id\": first_row[\"thread_id\"],\n",
    "        \"metadata_dict\": first_row\n",
    "    })\n",
    "\n",
    "df1_cleaned_merged = df1.groupby(\"thread_id\").apply(merge_metadata).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44bd7632-0306-43b1-b830-fce33372f43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>metadata_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'thread_id': 1, 'subject': 'FW: Master Termin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{'thread_id': 2, 'subject': 'Credit Group Lunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{'thread_id': 3, 'subject': 'New Address', 'ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{'thread_id': 4, 'subject': 'EOL Data', 'times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>{'thread_id': 5, 'subject': 'RE: long form con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>{'thread_id': 6, 'subject': 'BABY!', 'timestam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>{'thread_id': 7, 'subject': 'Canadian utilitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>{'thread_id': 8, 'subject': 'RE: Golf Anyone?'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>{'thread_id': 9, 'subject': 'RE: YO', 'timesta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>{'thread_id': 10, 'subject': 'RE: NNG/Dynegy D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>{'thread_id': 11, 'subject': 'CATS litigation'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>{'thread_id': 12, 'subject': 'RE: Kevin A. How...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>{'thread_id': 13, 'subject': 'Citizens request...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>{'thread_id': 14, 'subject': 'Cal-ISO Wants Pw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>{'thread_id': 15, 'subject': 'Index forwards/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>{'thread_id': 16, 'subject': 'Update to Approv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>{'thread_id': 17, 'subject': 'PLEASE READ', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>{'thread_id': 18, 'subject': 'Undeliverable: M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>{'thread_id': 19, 'subject': 'RE: ENRON/ALLEGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>{'thread_id': 20, 'subject': 'RE: Northern Nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>{'thread_id': 21, 'subject': 'FW: Cost Center'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>{'thread_id': 22, 'subject': 'GPG Organization...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>{'thread_id': 23, 'subject': 'Instinet', 'time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>{'thread_id': 24, 'subject': 'Enron Teeside Op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>{'thread_id': 25, 'subject': 'El Paso Merchant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>{'thread_id': 26, 'subject': 'Southwest Gas-Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>{'thread_id': 27, 'subject': 'RE: Admission Vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>{'thread_id': 28, 'subject': 'It could happen!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>{'thread_id': 29, 'subject': 'ClickPaper appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>{'thread_id': 30, 'subject': 'Legal Conference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>{'thread_id': 31, 'subject': 'Revised Docs', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>{'thread_id': 32, 'subject': 'RE: NG deal in C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>{'thread_id': 33, 'subject': 'FW: Summer Inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>{'thread_id': 34, 'subject': 'Limits', 'timest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>{'thread_id': 35, 'subject': 'RE: Mon morning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>{'thread_id': 36, 'subject': 'Morgan Stanley C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>{'thread_id': 37, 'subject': 'ENSIDE Newslette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>{'thread_id': 38, 'subject': 'BP Amoco', 'time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>{'thread_id': 39, 'subject': 'RE: Numbers', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>{'thread_id': 40, 'subject': 'Meeting with Da ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thread_id                                      metadata_dict\n",
       "0           1  {'thread_id': 1, 'subject': 'FW: Master Termin...\n",
       "1           2  {'thread_id': 2, 'subject': 'Credit Group Lunc...\n",
       "2           3  {'thread_id': 3, 'subject': 'New Address', 'ti...\n",
       "3           4  {'thread_id': 4, 'subject': 'EOL Data', 'times...\n",
       "4           5  {'thread_id': 5, 'subject': 'RE: long form con...\n",
       "5           6  {'thread_id': 6, 'subject': 'BABY!', 'timestam...\n",
       "6           7  {'thread_id': 7, 'subject': 'Canadian utilitie...\n",
       "7           8  {'thread_id': 8, 'subject': 'RE: Golf Anyone?'...\n",
       "8           9  {'thread_id': 9, 'subject': 'RE: YO', 'timesta...\n",
       "9          10  {'thread_id': 10, 'subject': 'RE: NNG/Dynegy D...\n",
       "10         11  {'thread_id': 11, 'subject': 'CATS litigation'...\n",
       "11         12  {'thread_id': 12, 'subject': 'RE: Kevin A. How...\n",
       "12         13  {'thread_id': 13, 'subject': 'Citizens request...\n",
       "13         14  {'thread_id': 14, 'subject': 'Cal-ISO Wants Pw...\n",
       "14         15  {'thread_id': 15, 'subject': 'Index forwards/s...\n",
       "15         16  {'thread_id': 16, 'subject': 'Update to Approv...\n",
       "16         17  {'thread_id': 17, 'subject': 'PLEASE READ', 't...\n",
       "17         18  {'thread_id': 18, 'subject': 'Undeliverable: M...\n",
       "18         19  {'thread_id': 19, 'subject': 'RE: ENRON/ALLEGH...\n",
       "19         20  {'thread_id': 20, 'subject': 'RE: Northern Nat...\n",
       "20         21  {'thread_id': 21, 'subject': 'FW: Cost Center'...\n",
       "21         22  {'thread_id': 22, 'subject': 'GPG Organization...\n",
       "22         23  {'thread_id': 23, 'subject': 'Instinet', 'time...\n",
       "23         24  {'thread_id': 24, 'subject': 'Enron Teeside Op...\n",
       "24         25  {'thread_id': 25, 'subject': 'El Paso Merchant...\n",
       "25         26  {'thread_id': 26, 'subject': 'Southwest Gas-Pe...\n",
       "26         27  {'thread_id': 27, 'subject': 'RE: Admission Vi...\n",
       "27         28  {'thread_id': 28, 'subject': 'It could happen!...\n",
       "28         29  {'thread_id': 29, 'subject': 'ClickPaper appro...\n",
       "29         30  {'thread_id': 30, 'subject': 'Legal Conference...\n",
       "30         31  {'thread_id': 31, 'subject': 'Revised Docs', '...\n",
       "31         32  {'thread_id': 32, 'subject': 'RE: NG deal in C...\n",
       "32         33  {'thread_id': 33, 'subject': 'FW: Summer Inter...\n",
       "33         34  {'thread_id': 34, 'subject': 'Limits', 'timest...\n",
       "34         35  {'thread_id': 35, 'subject': 'RE: Mon morning ...\n",
       "35         36  {'thread_id': 36, 'subject': 'Morgan Stanley C...\n",
       "36         37  {'thread_id': 37, 'subject': 'ENSIDE Newslette...\n",
       "37         38  {'thread_id': 38, 'subject': 'BP Amoco', 'time...\n",
       "38         39  {'thread_id': 39, 'subject': 'RE: Numbers', 't...\n",
       "39         40  {'thread_id': 40, 'subject': 'Meeting with Da ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_cleaned_merged.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "331288f7-b2f7-4f0d-b9b2-8344493655c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n -----Original Message-----\\nFrom: =09Theriot, Kim S. =20\\nSent:=09Tuesday, January 29, 2002 1:23 PM\\nTo:=09Richardson, Stacey; Anderson, Diane; Gossett, Jeffrey C.; White, Stac=\\ney W.; Murphy, Melissa; Hall, D. Todd; Sweeney, Kevin\\nCc:=09Aucoin, Evelyn; Baxter, Bryce; Wynne, Rita\\nSubject:=09FW: Master Termination Log\\n\\n\\n\\n -----Original Message-----\\nFrom: =09Panus, Stephanie =20\\nSent:=09Tuesday, January 29, 2002 11:39 AM\\nTo:=09Adams, Laurel; Alonso, Tom; Aronowitz, Alan; Bailey, Susan; Balfour-F=\\nlanagan, Cyndie; Baughman, Edward; Belden, Tim; Bishop, Serena; Brackett, D=\\nebbie R.; Bradford, William S.; Browning, Mary Nell; Bruce, James; Bruce, M=\\nichelle; Bruce, Robert; Buerkle, Jim; Calger, Christopher F.; Carrington, C=\\nlara; Considine, Keith; Cordova, Karen A.; Crandall, Sean; Cutsforth, Diane=\\n; Diamond, Russell; Dunton, Heather; Edison, Susan; Elafandi, Mo; Fischer, =\\nMark; Flores, Nony; Fondren, Mark; Gorny, Vladimir; Gorte, David; Gresham, =\\nWayne; Hagelmann, Bjorn; Hall, Steve C. (Legal); Harkness, Cynthia; Hendry,=\\n Brent; Johnston, Greg; Keohane, Peter; Lindeman, Cheryl; Little, Kelli; Ma=\\nllory, Chris; Mann, Kay; Mcginnis, Stephanie; McGrory, Robert; McMichael Jr=\\n., Ed; Miller, Don (Asset Mktg); Moore, Janet H.; Moran, Tom; Murphy, Harla=\\nn; Murray, Julia; Nemec, Gerald; Ogden, Mary; Otto, Randy; Page, Jonalan; P=\\nostlethwaite, John; Prejean, Frank; Presto, Kevin M.; Puchot, Paul; Rasmuss=\\nen, Dale; Richter, Brad; Richter, Jeff; Robison, Michael A.; Rohauer, Tanya=\\n; Rosman, Stewart; Runswick, Stacy; Sacks, Edward; Scholtes, Diana; Shackle=\\nton, Sara; Simons, Paul; Swinney, John; Thapar, Raj; Theriot, Kim S.; Thoma=\\ns, Jake; Thome, Stephen; Tricoli, Carl; Van Hooser, Steve; Wente, Laura; Wi=\\nlson, Shona; Winfree, O\\'Neal D.; Woodland, Andrea; Yoder, Christian\\nSubject:=09Master Termination Log\\n\\nAttached is the Daily Termination List for January 25 as well as the Master=\\n Termination Log, which incorporates all terminations received through Janu=\\nary 25.\\n\\n =20\\n\\nThe following were previously on the Master Termination Log and have now be=\\nen marked as \"Y\" for a valid termination:\\n\\nAtlantic Coast Fibers, Inc.=09=09=09ENA=09=09pulp/paper transactions\\nCNC-Containers Corporation=09=09=09EPMI=09=09master power agreement\\nPublic Utility District No. 1 of Chelan County=09EPMI=09=09deal no. 757497.=\\n01\\nConnect Energy Services, Inc.=09=09=09ENA=09=09liquids agreement\\nNGL Supply, Inc. (including Premier=09=09ENA/EGLI=09physical & financial tr=\\nansactions referenced\\nEnergy Partners, a division of NGL Supply, Inc.)\\nPlains Marketing, L.P.=09=09=09=09ERAC=09=09deal no. QG4563.1\\nPlains Marketing, L.P.=09=09=09=09ERAC=09=09deal no. QG4482.2\\n\\nStephanie Panus\\nEnron Wholesale Services\\nph:  713.345.3249\\nfax:  713.646.3490\\n\\n\\n\\n -----Original Message-----\\nFrom: =09Panus, Stephanie =20\\nSent:=09Thursday, January 31, 2002 12:08 PM\\nTo:=09Adams, Laurel; Albrecht, Kristin; Alonso, Tom; Aronowitz, Alan; Baile=\\ny, Susan; Balfour-Flanagan, Cyndie; Baughman, Edward; Belden, Tim; Bishop, =\\nSerena; Boyd, Samantha; Brackett, Debbie R.; Bradford, William S.; Browning=\\n, Mary Nell; Bruce, James; Bruce, Michelle; Bruce, Robert; Buerkle, Jim; Ca=\\nlger, Christopher F.; Carrington, Clara; Considine, Keith; Cordova, Karen A=\\n.; Crandall, Sean; Cutsforth, Diane; Diamond, Russell; Dunton, Heather; Edi=\\nson, Susan; Elafandi, Mo; Fischer, Mark; Flores, Nony; Fondren, Mark; Gorny=\\n, Vladimir; Gorte, David; Gresham, Wayne; Hagelmann, Bjorn; Hall, Steve C. =\\n(Legal); Harkness, Cynthia; Hendry, Brent; Johnston, Greg; Keohane, Peter; =\\nLindeman, Cheryl; Mallory, Chris; Mann, Kay; Mcginnis, Stephanie; McGrory, =\\nRobert; McMichael Jr., Ed; Miller, Don (Asset Mktg); Moore, Janet H.; Moran=\\n, Tom; Murphy, Harlan; Murray, Julia; Nemec, Gerald; Ogden, Mary; Page, Jon=\\nalan; Postlethwaite, John; Prejean, Frank; Presto, Kevin M.; Puchot, Paul; =\\nRasmussen, Dale; Richardson, Stacey; Richter, Brad; Richter, Jeff; Robison,=\\n Michael A.; Rohauer, Tanya; Rosman, Stewart; Sacks, Edward; Scholtes, Dian=\\na; Sevitz, Robert; Shackleton, Sara; Simons, Paul; Swinney, John; Thapar, R=\\naj; Theriot, Kim S.; Thomas, Jake; Thome, Stephen; Tricoli, Carl; Van Hoose=\\nr, Steve; Wente, Laura; Wilson, Shona; Winfree, O\\'Neal D.; Woodland, Andrea=\\n; Yoder, Christian\\nSubject:=09Master Termination Log\\n\\nAttached are the Daily Lists for January 29 and January 30 as well as the M=\\naster Termination Log, which incorporates all terminations received through=\\n January 30.  Also, prepetition mutual terminations have been added to this=\\n list.  They are identified under \"Nature of Default\" as \"mutual terminatio=\\nn\".\\n\\n  =20\\n\\nStephanie Panus\\nEnron Wholesale Services\\nph:  713.345.3249\\nfax:  713.646.3490\\n\\nNote to Stephanie Panus....\\n\\nStephanie...please remove my name as well as Melissa Murphy\\'s from the dist=\\nribution list below.\\n\\nPlease add the following:\\n\\nTodd D. Hall\\nKevin Sweeney\\nRita Wynne\\nRebecca Grace\\nRhonda Robinson\\nKerri Thomspon\\nKristin Albrecht\\nTom Chapman\\n\\n\\nThanks!\\n\\nKim Theriot\\n\\n -----Original Message-----\\nFrom: =09Panus, Stephanie =20\\nSent:=09Tuesday, February 05, 2002 8:18 AM\\nTo:=09Adams, Laurel; Albrecht, Kristin; Alonso, Tom; Aronowitz, Alan; Baile=\\ny, Susan; Balfour-Flanagan, Cyndie; Baughman, Edward; Belden, Tim; Bishop, =\\nSerena; Boyd, Samantha; Brackett, Debbie R.; Bradford, William S.; Browning=\\n, Mary Nell; Bruce, James; Bruce, Michelle; Bruce, Robert; Buerkle, Jim; Ca=\\nlger, Christopher F.; Carrington, Clara; Chilkina, Elena; Considine, Keith;=\\n Cordova, Karen A.; Crandall, Sean; Cutsforth, Diane; Diamond, Russell; Dun=\\nton, Heather; Edison, Susan; Elafandi, Mo; Fischer, Mark; Flores, Nony; Fon=\\ndren, Mark; Gorny, Vladimir; Gorte, David; Gresham, Wayne; Hagelmann, Bjorn=\\n; Hall, Steve C. (Legal); Harkness, Cynthia; Hendry, Brent; Johnston, Greg;=\\n Keohane, Peter; Lindeman, Cheryl; Mallory, Chris; Mann, Kay; Mcginnis, Ste=\\nphanie; McGrory, Robert; McMichael Jr., Ed; Miller, Don (Asset Mktg); Moore=\\n, Janet H.; Moran, Tom; Murphy, Harlan; Murray, Julia; Nemec, Gerald; Ogden=\\n, Mary; Page, Jonalan; Postlethwaite, John; Prejean, Frank; Presto, Kevin M=\\n.; Puchot, Paul; Rasmussen, Dale; Richardson, Stacey; Richter, Brad; Richte=\\nr, Jeff; Robison, Michael A.; Rohauer, Tanya; Rosman, Stewart; Sacks, Edwar=\\nd; Scholtes, Diana; Sevitz, Robert; Shackleton, Sara; Simons, Paul; Swinney=\\n, John; Thapar, Raj; Theriot, Kim S.; Thomas, Jake; Thome, Stephen; Tricoli=\\n, Carl; Van Hooser, Steve; Wente, Laura; Wilson, Shona; Winfree, O\\'Neal D.;=\\n Woodland, Andrea; Yoder, Christian\\nSubject:=09Master Termination Log\\n\\nAttached is the Daily List for January 31 as well as the Master Termination=\\n Log, which incorporates all terminations received through January 31.\\n\\n =20\\n\\nStephanie Panus\\nEnron Wholesale Services\\nph:  713.345.3249\\nfax:  713.646.3490\\n\\n\\n\\n -----Original Message-----\\nFrom: =09Panus, Stephanie =20\\nSent:=09Tuesday, February 05, 2002 4:59 PM\\nTo:=09Adams, Laurel; Albrecht, Kristin; Alonso, Tom; Aronowitz, Alan; Baile=\\ny, Susan; Balfour-Flanagan, Cyndie; Baughman, Edward; Belden, Tim; Bishop, =\\nSerena; Boyd, Samantha; Brackett, Debbie R.; Bradford, William S.; Browning=\\n, Mary Nell; Bruce, James; Bruce, Michelle; Bruce, Robert; Buerkle, Jim; Ca=\\nlger, Christopher F.; Carrington, Clara; Chilkina, Elena; Considine, Keith;=\\n Cordova, Karen A.; Crandall, Sean; Cutsforth, Diane; Diamond, Russell; Dun=\\nton, Heather; Edison, Susan; Elafandi, Mo; Fischer, Mark; Flores, Nony; Fon=\\ndren, Mark; Glover, Sheila; Gorny, Vladimir; Gorte, David; Gresham, Wayne; =\\nHagelmann, Bjorn; Hall, Steve C. (Legal); Harkness, Cynthia; Hendry, Brent;=\\n Johnston, Greg; Keohane, Peter; Lindeman, Cheryl; Mallory, Chris; Mann, Ka=\\ny; Mcginnis, Stephanie; McGrory, Robert; McMichael Jr., Ed; Miller, Don (As=\\nset Mktg); Moore, Janet H.; Moran, Tom; Murphy, Harlan; Murray, Julia; Neme=\\nc, Gerald; Ogden, Mary; Page, Jonalan; Postlethwaite, John; Prejean, Frank;=\\n Presto, Kevin M.; Puchot, Paul; Rasmussen, Dale; Richardson, Stacey; Richt=\\ner, Brad; Richter, Jeff; Robison, Michael A.; Rohauer, Tanya; Rosman, Stewa=\\nrt; Sacks, Edward; Scholtes, Diana; Sevitz, Robert; Shackleton, Sara; Simon=\\ns, Paul; Swinney, John; Thapar, Raj; Theriot, Kim S.; Thomas, Jake; Thome, =\\nStephen; Tricoli, Carl; Van Hooser, Steve; Wente, Laura; Wilson, Shona; Win=\\nfree, O\\'Neal D.; Woodland, Andrea; Yoder, Christian\\nSubject:=09Master Termination Log\\n\\nAttached is the Daily List for February 4 as well as the Master Termination=\\n Log, which incorporates all termination received through February 4 (with =\\nthe exception of February 1, which is under legal review and contains all f=\\ninancial transactions).\\n\\n =20\\n\\nStephanie Panus\\nEnron Wholesale Services\\nph:  713.345.3249\\nfax:  713.646.3490\\n\\n\\n\\n -----Original Message-----\\nFrom: =09McMichael Jr., Ed =20\\nSent:=09Tuesday, May 28, 2002 8:15 AM\\nTo:=09Lagrasta, Fred; Kelly, Katherine L.; Versen, Victoria\\nSubject:=09FW: Master Termination Log\\n\\nPlease look into the CNG LDC (Hope Gas) termination 12/1 and the $66 MM set=\\ntlement offer that is listed on the Letter Log below.  Let me know what tha=\\nt is after you figure it out.  If you have any questions, please ask.\\nEd  =20\\n\\n -----Original Message-----\\nFrom: =09Panus, Stephanie =20\\nSent:=09Friday, May 24, 2002 3:49 PM\\nTo:=09Adams, Laurel; Alon, Heather; Apollo, Beth; Arnold, Matthew; Aronowit=\\nz, Alan; Bailey, Susan; Balfour-Flanagan, Cyndie; Barbe, Robin; Baughman, E=\\ndward; Berryman, Kyle; Bolt, Laurel; Botello, Rose; Boudreau, Kara; Brennig=\\n, Tammy; Bridges, Michael; Bruck, Sarah; Camarillo, Juan; Coleman, David; C=\\nomeaux, Clinton; Concannon, Ruth; Cordova, Karen A.; Couch, Greg; Danaher, =\\nPatrick; Darmitzel, Paul; Del vecchio, Peter; Despres, Dan; Dicarlo, Louis;=\\n Edison, Susan; Elafandi, Mo; Fay, Ashley; Flores, Nony; Fowler, Kulvinder;=\\n Garza, Maria; Germany, Chris; Gonzalez, Victor; Gorte, David; Grace, Rebec=\\nca M.; Guillen, Andrea R.; Hagelmann, Bjorn; Haralson, Nancy L; Harkness, C=\\nynthia; Herrera, Olga; Heuertz, Kelly; Hoang, Charlie; Johnson, Luchas; Kel=\\nler, James E.; Lagrasta, Fred; Leuschen, Sam; Lindeman, Cheryl; Lowry, Donn=\\na; Mann, Kay; Matheson, A.k.; Mausser, Gregory A.; McClure, Zakiyyah; McMic=\\nhael Jr., Ed; Miller, Don (Asset Mktg); Moore, Janet H.; Moscoso, Michael E=\\n.; Muench, Gayle W.; Murphy, Harlan; Murray, Julia; Nelson, Michelle; Polsk=\\ny, Phil; Prejean, Frank; Puchot, Paul; Richard, Robert; Richardson, Stacey;=\\n Roberson, Weezie ; Robison, Michael A.; Sacchi, Martin; Sayre, Frank; Sevi=\\ntz, Robert; Shackleton, Sara; Sharma, Shifali; Shivers, Lynn; Shoup, Cynthi=\\na; Smida, Ed; Stai, Aaron ; Sweeney, Kevin; Thapar, Raj; Thibaut, Dan; Tric=\\noli, Carl; Versen, Victoria; Ward, Charles; Wilson, Shona; Wolgel, Fred\\nSubject:=09Master Termination Log\\n\\nAttached is the Daily List for May 24, 2002 as well as the Master Terminati=\\non Log, which incorporates all terminations received through May 24.\\n\\n =20\\n\\nStephanie Panus\\nEnron Wholesale Services\\nph:  713.345.3249\\nfax:  713.646.3490'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_cleaned_merged[df1_cleaned_merged[\"thread_id\"] == 1][\"metadata_dict\"].iloc[0][\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e55185-f99e-4abb-99cb-894afe62ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Merge df1_cleaned_merged with df2 on thread_id\n",
    "merged_df = pd.merge(df1_cleaned_merged, df2, on=\"thread_id\", how=\"left\")\n",
    "\n",
    "# Step 2: Add 'summary' to metadata_dict\n",
    "merged_df[\"metadata_dict\"] = merged_df.apply(\n",
    "    lambda row: {**row[\"metadata_dict\"], \"summary\": row[\"summary\"]},\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optional: drop the now-redundant summary column\n",
    "merged_df = merged_df.drop(columns=[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8df2001-35e0-4cef-96f0-fff44b41c52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>metadata_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'thread_id': 1, 'subject': 'FW: Master Termin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{'thread_id': 2, 'subject': 'Credit Group Lunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{'thread_id': 3, 'subject': 'New Address', 'ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{'thread_id': 4, 'subject': 'EOL Data', 'times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>{'thread_id': 5, 'subject': 'RE: long form con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>4163</td>\n",
       "      <td>{'thread_id': 4163, 'subject': 'ltr to Kay Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>4164</td>\n",
       "      <td>{'thread_id': 4164, 'subject': 'presentation',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>4165</td>\n",
       "      <td>{'thread_id': 4165, 'subject': 'this weekend',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>4166</td>\n",
       "      <td>{'thread_id': 4166, 'subject': 'vacation', 'ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>4167</td>\n",
       "      <td>{'thread_id': 4167, 'subject': 'web file', 'ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      thread_id                                      metadata_dict\n",
       "0             1  {'thread_id': 1, 'subject': 'FW: Master Termin...\n",
       "1             2  {'thread_id': 2, 'subject': 'Credit Group Lunc...\n",
       "2             3  {'thread_id': 3, 'subject': 'New Address', 'ti...\n",
       "3             4  {'thread_id': 4, 'subject': 'EOL Data', 'times...\n",
       "4             5  {'thread_id': 5, 'subject': 'RE: long form con...\n",
       "...         ...                                                ...\n",
       "4162       4163  {'thread_id': 4163, 'subject': 'ltr to Kay Man...\n",
       "4163       4164  {'thread_id': 4164, 'subject': 'presentation',...\n",
       "4164       4165  {'thread_id': 4165, 'subject': 'this weekend',...\n",
       "4165       4166  {'thread_id': 4166, 'subject': 'vacation', 'ti...\n",
       "4166       4167  {'thread_id': 4167, 'subject': 'web file', 'ti...\n",
       "\n",
       "[4167 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "022d9b7c-1e21-4c2b-b758-0bbf5eb06087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The email thread discusses the Master Termination Log and the need to investigate a CNG LDC (Hope Gas) termination and a $66 million settlement offer. Stephanie Panus sends out the Daily List and Master Termination Log for various dates. Kim Theriot requests her name and Melissa Murphy's name to be removed from the distribution list and adds several names to it. The thread also includes updates on terminations and valid terminations for various companies.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df[\"thread_id\"] == 1][\"metadata_dict\"].iloc[0][\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78a9bd75-fab5-4752-94db-598268edae63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FW: Master Termination Log'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df[\"thread_id\"] == 1][\"metadata_dict\"].iloc[0][\"subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aff2e01-7e0b-4deb-b409-a93285dd4c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = merged_df['metadata_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "751736fd-ca58-402c-9d87-b8ca4cf7f3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {'thread_id': 1, 'subject': 'FW: Master Termin...\n",
       "1       {'thread_id': 2, 'subject': 'Credit Group Lunc...\n",
       "2       {'thread_id': 3, 'subject': 'New Address', 'ti...\n",
       "3       {'thread_id': 4, 'subject': 'EOL Data', 'times...\n",
       "4       {'thread_id': 5, 'subject': 'RE: long form con...\n",
       "                              ...                        \n",
       "4162    {'thread_id': 4163, 'subject': 'ltr to Kay Man...\n",
       "4163    {'thread_id': 4164, 'subject': 'presentation',...\n",
       "4164    {'thread_id': 4165, 'subject': 'this weekend',...\n",
       "4165    {'thread_id': 4166, 'subject': 'vacation', 'ti...\n",
       "4166    {'thread_id': 4167, 'subject': 'web file', 'ti...\n",
       "Name: metadata_dict, Length: 4167, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f0ed7e-6db8-40a5-9d4a-cb6d405dea8a",
   "metadata": {},
   "source": [
    "### Step3: Create langchain document object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea32cfac-9016-4fda-a142-e012f7c0b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=row[\"body\"],  # Use the full thread body for vector search\n",
    "        metadata=row  # Include all metadata: subject, summary, to, from, etc.\n",
    "    )\n",
    "    for row in final_df\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0fb14-07a1-4bce-b8ae-3720fcfaead4",
   "metadata": {},
   "source": [
    "### Step4: Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1350e9f8-e478-4dab-a6bb-c2238ace715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "chunked_documents = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86c879-09cc-447d-b63e-4c7fb1e8ff02",
   "metadata": {},
   "source": [
    "#### Reading Open API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc6b2ff8-b25b-4a01-b938-b35fa9ab3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3921146a-96e4-4b60-ab38-c98a3bccbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path\n",
    "with open(\"keys.txt\", \"r\") as file:\n",
    " os.environ[\"OPENAI_API_KEY\"] = file.read().strip()  # Removes extra spaces/newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bee1f98-9a8d-41b9-9e15-b5a4554b8616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.11/site-packages (4.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dab9014f-64bd-4ac8-b4ac-d087c98efda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "551d0037-2678-4258-a42d-31262c2937de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a490b9e-4b76-4b50-a338-74cf04551acd",
   "metadata": {},
   "source": [
    "### Step5: Embedding and Vector store creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f08589d-b824-486a-aba9-b3111cc8082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(chunked_documents, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58983d61-e269-49d5-a5d4-827931fd7b0d",
   "metadata": {},
   "source": [
    "### Step6: Set up a Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95cddaa1-feaa-4301-8030-d6c6247101b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa2085-03b9-4ce1-b839-d3edd6840b8f",
   "metadata": {},
   "source": [
    "### Step7: Generative QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a24bddc9-dce4-47e9-ac5f-ebbe8f01bba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/5f3_2qps7jj4s6z2p3k48qjh0000gn/T/ipykernel_75596/1518811646.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4eca116d-6ff9-4e9d-be0b-96d72be9ad9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " The House of Lords planned to give their decision in the CATS litigation on Wednesday, April 4.\n",
      "\n",
      "--- Source Document 1 ---\n",
      "\n",
      "----- Forwarded by Richard B Sanders/HOU/ECT on 03/30/2001 10:01 AM -----\n",
      "\n",
      "\tMary Nell Browning\n",
      "\t03/30/2001 09:12 AM\n",
      "\t\t \n",
      "\t\t To: James Derrick/Corp/Enron, Michael R Brown/LON/ECT@ECT, John \n",
      "Sherriff/LON/ECT@ECT, Mark Evans/Legal/LON/ECT@ECT, Richard B \n",
      "Sanders/HOU/ECT@ECT, Fernley Dyson/LON/ECT@ECT, Paul Chivers/LON/ECT@ECT, \n",
      "Richard Lewis/LON/ECT@ECT, Peter Crilly/LON/ECT@ECT, Richard \n",
      "Harper/LON/ECT@ECT, Paul Turner/LON/ECT@ECT, Jackie Gentle/LON/ECT@ECT, \n",
      "Claire Wright/LON/ECT@ECT, Raj N Patel \n",
      "\n",
      "--- Source Document 2 ---\n",
      "\n",
      "Disappointingly, the House of Lords ruled 5 - 0 against Enron in the CATS \n",
      "litigation today.  This will mean that we will repay to the CATS parties \n",
      "approximately $150 million plus interest and court costs, putting the final \n",
      "figure at an estimated $155-160 million.  We expect to be invoiced for the \n",
      "principal amount in the next week or so; sorting costs and interest may take \n",
      "as long as 60 days.  The written opinion reflects a determination on the part \n",
      "of the Lords to rule against us regardles\n",
      "\n",
      "--- Source Document 3 ---\n",
      "\n",
      "Equally disappointing and surprising is the fact that the Lords rejected our \n",
      "submission for reimbursement of our costs incurred in connection with the \n",
      "restitution issue.  As you may recall, restitution was the primary issue upon \n",
      "which the CATS parties obtained leave to appeal, and they conceded the point \n",
      "at the commencement of the hearing.  Reimbursement of these costs should have \n",
      "been a given. \n",
      "\n",
      "Although I have not yet been able to speak to our most senior barrister, our \n",
      "other counsel hav\n",
      "\n",
      "--- Source Document 4 ---\n",
      "\n",
      "This is so precious!!!\n",
      "\n",
      "For the cat lovers!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " - w&N)TS.mpe\n",
      "\n",
      "For the cat lovers!\n",
      "\n",
      "\n",
      "\n",
      " - w&N)TS.mpe\n",
      "\n",
      " - w&N)TS.mpe\n",
      "\n",
      "Debra Perlingiere\n",
      "Enron North America Corp.\n",
      "Legal Department\n",
      "1400 Smith Street, EB 3885\n",
      "Houston, Texas 77002\n",
      "dperlin@enron.com\n",
      "Phone 713-853-7658\n",
      "Fax  713-646-3490\n",
      "\n",
      "----- Forwarded by Debra Perlingiere/HOU/ECT on 12/12/2000 09:30 AM -----\n",
      "\n",
      "\tGenia FitzGerald\n",
      "\t12/05/2000 01:37 PM\n",
      "\t\t \n",
      "\t\t To: Kimberlee A Bennick/HOU/ECT@ECT, Debra Perlingiere/HOU/ECT@ECT\n",
      "\t\t cc: \n",
      "\t\t Subject: Sleepy\n",
      "\n",
      "\n",
      "\n",
      "--- Source Document 5 ---\n",
      "\n",
      "Prior to the CATS shutdown, we had made them a proposal to enable them to \n",
      "deliver additional volumes at  another alternative to avoid default but they \n",
      "have not responded yet.\n",
      "\n",
      "You mentioned that in your negotiations with Phillips they had committed to \n",
      "getting us all the gas regardless of the cap on the penalties.  This has cost \n",
      "us about $1.5 million to date and they seem to be institutionalising their \n",
      "non performance.    Perhaps a phone call by you might help.  \n",
      "\n",
      "By the way I will be in Hou\n"
     ]
    }
   ],
   "source": [
    "query = \"When is House of Lords planning to give decision in CATS litigation\"\n",
    "\n",
    "response = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"Answer:\\n\", response['result'])\n",
    "\n",
    "# Optional: Check sources\n",
    "for i, doc in enumerate(response['source_documents']):\n",
    "    print(f\"\\n--- Source Document {i+1} ---\\n\")\n",
    "    print(doc.page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "372fc38b-5959-4680-b741-0ffbafa03087",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"When is House of Lords planning to give decision in CATS litigation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81686caf-0c87-417e-93d8-7d766b59b259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The House of Lords planned to give their decision in the CATS litigation on Wednesday, 4th April.\n"
     ]
    }
   ],
   "source": [
    "answer = qa_chain.invoke({\"query\": query1})['result']\n",
    "print(answer.strip().split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1aca9410-6e10-4c1f-a4f5-99b8f182dcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kevin A. Howard was appointed as Vice President of ETS, TW, and NNG effective November 12, 2001. His job description involved commercial and financial transactions support. King Jr. was coordinating with Miranda to update the organizational charts for TW and NNG to include Kevin A. Howard. There was a discussion about Kevin reporting to Rod, and questions were raised about his placement on the organizational charts under Saunders and Peters, as well as in the Finance and Accounting charts. Bill confirmed that Kevin would be reporting to Rod and that his title would be Vice President, Commercial and Financial Transactions Support.\n"
     ]
    }
   ],
   "source": [
    "query2 = \"What is the summary of conversation between Kevin A. Howard and King Jr.\"\n",
    "print((qa_chain.invoke({\"query\": query2})['result']).strip().split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ba369d5-ff6e-4876-8ccd-c95bbe874839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob Badeer has become the leader of the project by default, as mentioned in the email chain.\n"
     ]
    }
   ],
   "source": [
    "query3 = \"As per mail chain Index forwards/swaps who has become the leader of the project by default\"\n",
    "print((qa_chain.invoke({\"query\": query3})['result']).strip().split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd5b7595-ac3b-4bca-9670-4f06e1dcd22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before being transferred to the gas pipeline legal group, Bill Rapp was associated with the Enron Legal Department.\n"
     ]
    }
   ],
   "source": [
    "query4 = \"Before being transferred to gas pipeline legal group, Bill Rapp was associated with which department\"\n",
    "print((qa_chain.invoke({\"query\": query4})['result']).strip().split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55def492-dc3e-4d6e-9dc3-27ebd8a1f95d",
   "metadata": {},
   "source": [
    "#### We have built a simple QA Chain using where we are getting the desired answers for our queries from the list of the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d6aac-7531-4150-8ab0-c5e8433fc974",
   "metadata": {},
   "source": [
    "### Step8: Now let's build a conversational QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f741c0fd-046c-4781-9076-328bc8a7bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "# Create memory to store chat history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Define the retriever\n",
    "retriever_conversational = vectorstore.as_retriever()\n",
    "\n",
    "# Create the conversational QA chain\n",
    "coversational_qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatOpenAI(),  # can be any chat-capable LLM\n",
    "    retriever=retriever_conversational,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4be12d86-65fa-4d3a-82af-33aec35139cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = \"When is House of Lords planning to give decision in CATS litigation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24bc5cb3-3423-4ba1-909d-cc199eeff2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'When is House of Lords planning to give decision in CATS litigation', 'chat_history': [HumanMessage(content='When is House of Lords planning to give decision in CATS litigation', additional_kwargs={}, response_metadata={}), AIMessage(content='The House of Lords planned to give their decision in the CATS litigation on Wednesday 4 April.', additional_kwargs={}, response_metadata={}), HumanMessage(content='When is House of Lords planning to give decision in CATS litigation', additional_kwargs={}, response_metadata={}), AIMessage(content='The House of Lords is scheduled to deliver their decision in the CATS litigation on Wednesday, April 4.', additional_kwargs={}, response_metadata={}), HumanMessage(content='When is House of Lords planning to give decision in CATS litigation', additional_kwargs={}, response_metadata={}), AIMessage(content='The House of Lords was scheduled to deliver their decision in the CATS litigation on Wednesday, April 4th.', additional_kwargs={}, response_metadata={}), HumanMessage(content='When is House of Lords planning to give decision in CATS litigation', additional_kwargs={}, response_metadata={}), AIMessage(content='The House of Lords notified that they were planning to give their decision in the CATS litigation on Wednesday, 4 April.', additional_kwargs={}, response_metadata={})], 'answer': 'The House of Lords notified that they were planning to give their decision in the CATS litigation on Wednesday, 4 April.'}\n"
     ]
    }
   ],
   "source": [
    "print(coversational_qa_chain.invoke({\"question\": conv1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48b054b1-080f-42e1-8d86-f445ab0c9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The House of Lords planned to announce their decision in the CATS litigation on Wednesday, April 4.\n"
     ]
    }
   ],
   "source": [
    "print(coversational_qa_chain.invoke({\"question\": conv1})['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca63f094-efe8-4435-966f-aa328b92c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = \"So what was the final decision from House of Lords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09d1afee-cd28-43f4-918d-0131c919501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final decision from the House of Lords ruled against Enron in the CATS litigation, with a 5 - 0 decision. This meant that Enron would have to repay approximately $150 million plus interest and court costs, totaling an estimated $155-160 million. The Lords' decision was based on their interpretation of the contract and their assessment of Enron's entitlement to relief.\n"
     ]
    }
   ],
   "source": [
    "print(coversational_qa_chain.invoke({\"question\": conv2})['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4fbbda0-927e-45b2-b0a9-4a3bbb9f27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron was involved in a CATS litigation case where the House of Lords ruled against them, resulting in Enron having to repay approximately $150 million plus interest and court costs, totaling an estimated $155-160 million. The Lords' decision was based on their interpretation of the contract rather than the contract's provisions. The opinion highlighted issues such as the retroactive consequences of latent defects, the timing of obligations under the contract, and the effectiveness of notices sent by the CATS parties. Lord Hoffman, who authored the primary opinion, concluded that Enron was not entitled to relief under the contract because they were not ready to flow J-Block gas during a specific period. The ruling was seen as unfavorable to Enron, and despite the disappointment, the support received during the case was appreciated.\n"
     ]
    }
   ],
   "source": [
    "conv3 = \"Thanks can you give me the full summary of this case\"\n",
    "print(coversational_qa_chain.invoke({\"question\": conv3})['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f74c2-a539-4480-8662-02f23b336297",
   "metadata": {},
   "source": [
    "#### We see we are getting right results in form of the conversation and llm is able to undersatnd the context of current query based on the previous query "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60812e9d-a49e-46e1-9292-6dad3141dacf",
   "metadata": {},
   "source": [
    "## Summary\n",
    "#### We built a simple QA Chain (Question Answer) using Langchain where we can find answers for our query from the corpus of data, and we are getting more than 90% accuracy.\n",
    "#### Also we can build a conversational chain just like chatbots and we were able to maintain the history of conversation going. And answers provided by the conversational chain were based on the previous instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f4831-8751-4f0d-b973-a0e715016d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
